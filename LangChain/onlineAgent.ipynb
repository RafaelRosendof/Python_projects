{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testando\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nao pesquisar a peça retorne os veiculos que essa peça é compativel e as informações do veiculo em um formato json siga esse exemplo de baixo\\nExemplo:\\n\\n {\\n  'nome': stirng,\\n  'SKU': string,\\n  'application': string,\\n  'Marca': string\\n  }\\n\\n\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('testando')\n",
    "\n",
    "'''\n",
    "[{\n",
    "  'SKU': '087086',\n",
    "  'Marca': 'AJE INDUSTRIA'},\n",
    " {\n",
    "  'SKU': 'VS05610000001',\n",
    "  'Marca': 'VEDAMOTORS'},\n",
    "]\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    " {'id': 4483755,\n",
    "  'name': 'CAP LIBERTY COMPACT SUMMER BCO T58',\n",
    "  'manufacturer_ref': 'CAP466BC',\n",
    "  'application': 'UNIV',\n",
    "  'brand_name': 'PROTORK'},\n",
    " {'id': 4269305,\n",
    "  'name': 'LONA TRASEIRA',\n",
    "  'manufacturer_ref': '0137T140',\n",
    "  'application': 'MERCEDES BENZ PESADO - 1618 OF 1992\\nMERCEDES BENZ PESADO - 1620 OF 1993\\nMERCEDES BENZ PESADO - 1625 OH 1996\\nMERCEDES BENZ PESADO - 1635 OH 1995\\nMERCEDES BENZ PESADO - 1721 OF 1998\\n',\n",
    "  'brand_name': 'COBREQ'},\n",
    " {'id': 4443234,\n",
    "  'name': 'CAVALETE E',\n",
    "  'manufacturer_ref': '030470',\n",
    "  'application': 'HILUX 2.7 3.0 09/',\n",
    "  'brand_name': 'FINDER'}\n",
    "'''\n",
    "\n",
    "'''\n",
    "[{\n",
    "  'SKU': '087086',\n",
    "  'Marca': 'AJE INDUSTRIA'},\n",
    " {\n",
    "  'SKU': 'VS05610000001',\n",
    "  'Marca': 'VEDAMOTORS'},\n",
    "]\n",
    "'''\n",
    "\n",
    "'''\n",
    "ao pesquisar a peça retorne os veiculos que essa peça é compativel e as informações do veiculo em um formato json siga esse exemplo de baixo\n",
    "Exemplo:\n",
    "\n",
    " {\n",
    "  'nome': stirng,\n",
    "  'SKU': string,\n",
    "  'application': string,\n",
    "  'Marca': string\n",
    "  }\n",
    "Exemplo para seguir\n",
    " {\n",
    "  'nome': stirng,\n",
    "  'SKU': string,\n",
    "  'Aplicação': string,\n",
    "  'Marca': string\n",
    "  }\n",
    "  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_axe.agents import OnlineAgent\n",
    "from llm_axe.models import OllamaChat\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "Baseado na sku e no nome da marca voce consegue me detalhar a peça em um formato json?\n",
    "{\n",
    "  'SKU': '087086',\n",
    "  'Marca': 'AJE INDUSTRIA'\n",
    "}\n",
    "\n",
    "consiga o máximo de informações possíveis sobre a peça o que voce encontrar coloque em formato json\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model requires more system memory (37.3 GiB) than is available (6.2 GiB)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m OllamaChat(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3:70b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m searcher \u001b[38;5;241m=\u001b[39m OnlineAgent(llm)\n\u001b[0;32m----> 3\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp)\n",
      "File \u001b[0;32m~/anaconda3/envs/figas2/lib/python3.9/site-packages/llm_axe/agents.py:533\u001b[0m, in \u001b[0;36mOnlineAgent.search\u001b[0;34m(self, prompt, history)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03mSearches the internet and answers the prompt based on the search results.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m    str: The response that answers the prompt.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# Will first get a good search query\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;66;03m# The query will be used to find relevant URLS\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# The llm will pick the best URL and read it to answer the prompt\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_search_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/figas2/lib/python3.9/site-packages/llm_axe/agents.py:587\u001b[0m, in \u001b[0;36mOnlineAgent.get_search_query\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m    585\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m make_prompt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[1;32m    586\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_prompt, user_prompt]\n\u001b[0;32m--> 587\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m response_json \u001b[38;5;241m=\u001b[39m safe_read_json(response)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_history\u001b[38;5;241m.\u001b[39mappend(prompts[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/figas2/lib/python3.9/site-packages/llm_axe/models.py:21\u001b[0m, in \u001b[0;36mOllamaChat.ask\u001b[0;34m(self, prompts, format, temperature)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompts:\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mformat\u001b[39m:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature:\u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m        prompts (list): A list of prompts to ask.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        format (str, optional): The format of the response. Use \"json\" for json. Defaults to \"\".\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m        temperature (float, optional): The temperature of the LLM. Defaults to 0.8.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/figas2/lib/python3.9/site-packages/ollama/_client.py:236\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;241m:=\u001b[39m message\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    234\u001b[0m     message[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [_encode_image(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeep_alive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/figas2/lib/python3.9/site-packages/ollama/_client.py:99\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[0;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[1;32m     94\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m     96\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[0;32m---> 99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/figas2/lib/python3.9/site-packages/ollama/_client.py:75\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m   response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mResponseError\u001b[0m: model requires more system memory (37.3 GiB) than is available (6.2 GiB)"
     ]
    }
   ],
   "source": [
    "llm = OllamaChat(model=\"llama3:70b\")\n",
    "searcher = OnlineAgent(llm)\n",
    "resp = searcher.search(prompt)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I'm happy to help! However, I must clarify that there is no information about the products or their specifications in the provided text. The text appears to be a website configuration and copyright notice for AliExpress.com, but it does not contain any details about specific products or SKU numbers.\\n\\nBased on information from the internet, I would need more data or context to provide the requested information in JSON format. If you could provide me with the actual product specifications, including SKU numbers and brand names, I would be happy to assist you in retrieving that information.\"\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "from llm_axe.agents import OnlineAgent\n",
    "from llm_axe.models import OllamaChat\n",
    "import json\n",
    "\n",
    "# Função para validar a entrada do prompt\n",
    "def validate_input(prompt):\n",
    "    if not prompt.strip():\n",
    "        raise ValueError(\"O prompt não pode ser vazio.\")\n",
    "\n",
    "# Função para pesquisar peças\n",
    "def pesquisar_pecas(pecas):\n",
    "    prompt_base = \"\"\"\n",
    "    Olá, eu preciso que você pesquise essas peças com base nos SKU de cada peça e no nome da marca da peça. \n",
    "    Retorne o máximo de informações possíveis em um formato JSON das peças abaixo:\n",
    "    \"\"\"\n",
    "    prompt_pecas = json.dumps(pecas)  # Formata a lista de peças como JSON\n",
    "    prompt_final = prompt_base + prompt_pecas + \"\\nRetorne todas as informações possíveis sobre as peças em um formato JSON.\"\n",
    "\n",
    "    # Validação e execução\n",
    "    validate_input(prompt_final)\n",
    "    \n",
    "    llm = OllamaChat(model=\"llama3:instruct\")\n",
    "    searcher = OnlineAgent(llm)\n",
    "\n",
    "    try:\n",
    "        resp = searcher.search(prompt_final)\n",
    "        if resp is None:\n",
    "            raise Exception(\"A resposta retornada é vazia.\")\n",
    "        return resp\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de uso\n",
    "pecas = [\n",
    "    {'SKU': '087086', 'Marca': 'AJE INDUSTRIA'},\n",
    "    # Adicione mais peças conforme necessário\n",
    "]\n",
    "\n",
    "# Executando a pesquisa e imprimindo a resposta formatada\n",
    "resp = pesquisar_pecas(pecas)\n",
    "if resp is not None:\n",
    "    print(json.dumps(resp, indent=4, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "figas2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
